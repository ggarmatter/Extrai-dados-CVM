{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os.path\n",
    "import wget\n",
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variaveis globais\n",
    "\n",
    "#qual base de dados quero usar, \"con\" para consolidado e \"ind\" para individual\n",
    "tipo = \"con\"\n",
    "\n",
    "#Pega data corrente e ano corrente\n",
    "date = datetime.date.today()\n",
    "year = date.year\n",
    "\n",
    "# ano inicial pra coleta dos dados\n",
    "year_0 = 2010 \n",
    "year_0_tri = year-2 # ano inicial pra coletoa dos dados trimestrais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baixa todos os dados se não estiverem presentes, retorna uma lista de nomes de arquivos baixados\n",
    "def baixa_dados(year_0=year_0, year=year, year_0_tri=year_0_tri):\n",
    "    # URL's onde estão os arquivos dfp e itr na CVM\n",
    "    url_base = 'http://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/DFP/DADOS/'\n",
    "    url_base_fre = 'http://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/FRE/DADOS/'\n",
    "    url_base_tri = 'http://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/'\n",
    "    url_base_fca = \"https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/FCA/DADOS/\"\n",
    "\n",
    "    # Cria uma lista com os nomes dos arquivos de dados anuais (dfp) da CVM\n",
    "    arquivos_zip = []\n",
    "    for ano in range(year_0, year + 1):\n",
    "        arquivos_zip.append(f'dfp_cia_aberta_{ano}.zip')\n",
    "\n",
    "    # baixa os arquivos dfp\n",
    "    arquivos_zip_dfp_baixados = []\n",
    "    for arq in arquivos_zip:\n",
    "        if (os.path.isfile(f'./Data/{arq}')):\n",
    "            print('%s já esta aqui' % arq)\n",
    "            arquivos_zip_dfp_baixados.append(arq)\n",
    "        else:\n",
    "            try:\n",
    "                wget.download(url_base + arq, out=f\"./Data/{arq}\")\n",
    "                arquivos_zip_dfp_baixados.append(arq)\n",
    "            except:\n",
    "                print(f\"falha ao baixar {arq}\")\n",
    "                pass\n",
    "\n",
    "    # Cria lista de arquivos ITR (trimestrais) pra baixar\n",
    "    arquivos_zip = []\n",
    "    for ano in range(year_0_tri, year + 1):\n",
    "        arquivos_zip.append(f'itr_cia_aberta_{ano}.zip')\n",
    "\n",
    "    # baixa os arquivos ITR (dados trimestrais) se não estiverem presentes\n",
    "    arquivos_zip_itr_baixados = []\n",
    "    for arq in arquivos_zip:\n",
    "        if (os.path.isfile(f'./Data/{arq}')):\n",
    "            print('%s já esta aqui' % arq)\n",
    "            arquivos_zip_itr_baixados.append(arq)\n",
    "        else:\n",
    "            try:\n",
    "                wget.download(url_base_tri + arq, out=f\"./Data/{arq}\")\n",
    "                arquivos_zip_itr_baixados.append(arq)\n",
    "            except:\n",
    "                print(f\"falha ao baixar {arq}\")\n",
    "                pass\n",
    "\n",
    "    # baixa arquivo FCA, que contém os tickers\n",
    "\n",
    "    # Cria lista de arquivos FCA  pra baixar. Este aqui só precisa baixar o do último ano disponível\n",
    "    # Se não tiver do ano atual baixa o do ano passado\n",
    "    arquivos_zip = []\n",
    "    for ano in [year, year - 1]:\n",
    "        arquivos_zip.append(f'fca_cia_aberta_{ano}.zip')\n",
    "\n",
    "    arquivos_zip_fca_baixados = []\n",
    "    for arq in arquivos_zip:\n",
    "        if (os.path.isfile(f'./Data/{arq}')):\n",
    "            print('%s já esta aqui' % arq)\n",
    "            arquivos_zip_fca_baixados.append(arq)\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                wget.download(url_base_fca + arq, out=f\"./Data/{arq}\")\n",
    "                arquivos_zip_fca_baixados.append(arq)\n",
    "                break # se conseguiu baixar 1 já sai do loop\n",
    "            except:\n",
    "                print(f\"falha ao baixar {arq}\")\n",
    "    \n",
    "    # baixa arquivo FRE, que contém o número total de ações\n",
    "    \n",
    "    arquivos_zip = []\n",
    "    for ano in range(year-3, year+1):\n",
    "        print(ano)\n",
    "        arquivos_zip.append(f'fre_cia_aberta_{ano}.zip')\n",
    "\n",
    "    arquivos_zip_fre_baixados = []\n",
    "    for arq in arquivos_zip:\n",
    "        if (os.path.isfile(f'./Data/{arq}')):\n",
    "            print('%s já esta aqui' % arq)\n",
    "            arquivos_zip_fre_baixados.append(arq)\n",
    "        else:\n",
    "            try:\n",
    "                wget.download(url_base_fre + arq, out=f\"./Data/{arq}\")\n",
    "                arquivos_zip_fre_baixados.append(arq)\n",
    "            except:\n",
    "                print(f\"falha ao baixar {arq}\")\n",
    "                \n",
    "    return (arquivos_zip_dfp_baixados, arquivos_zip_itr_baixados, arquivos_zip_fca_baixados, arquivos_zip_fre_baixados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processa_dados(year_0=year_0, year=year, year_0_tri=year_0_tri):\n",
    "    print(\"Processando dados\")\n",
    "    # junta todos os anos de dados anuais em um arquivo só de cada tipo\n",
    "    nomes = ['BPA_con', 'BPA_ind', 'BPP_con', 'BPP_ind', 'DRE_con', 'DRE_ind',\n",
    "             'DFC_MD_con', 'DFC_MI_con', 'DFC_MD_ind', 'DFC_MI_ind']\n",
    "    for nome in nomes:\n",
    "        arquivo_bp = pd.DataFrame()\n",
    "        for ano in range(year_0, year):\n",
    "            try:\n",
    "                arquivo_bp = pd.concat([arquivo_bp,\n",
    "                                        pd.read_csv(f'./Data/temp/dfp_cia_aberta_{nome}_{ano}.csv', sep=';',\n",
    "                                                    decimal=',', encoding='ISO-8859-1')])\n",
    "            except:\n",
    "                print(f\"falha em {nome}\")\n",
    "                pass\n",
    "        arquivo_bp.to_csv(f'./Data/processados/dfp_cia_aberta_{nome}_{year_0}-{year}.csv', index=False, encoding=\"latin1\")\n",
    "        print(f'DFP {nome} processado')\n",
    "\n",
    "    # junta todos os anos de dados trimestrais em um arquivo só de cada tipo\n",
    "    nomes_tri = ['BPA_con', 'BPA_ind', 'BPP_con', 'BPP_ind', 'DRE_con', 'DRE_ind',\n",
    "                 \"DFC_MD_con\", \"DFC_MI_con\", \"DFC_MD_ind\", \"DFC_MI_ind\"]\n",
    "    for nome in nomes_tri:\n",
    "        arquivo_bp = pd.DataFrame()\n",
    "        for ano in range(year_0_tri, year + 1):\n",
    "            try:\n",
    "                arquivo_bp = pd.concat([arquivo_bp,\n",
    "                                        pd.read_csv(f'./Data/temp/itr_cia_aberta_{nome}_{ano}.csv', sep=';',\n",
    "                                                    decimal=',', encoding='ISO-8859-1')])\n",
    "            except:\n",
    "                print(f\"falha em itr_cia_aberta_{nome}_{ano}\")\n",
    "                pass\n",
    "        arquivo_bp.to_csv(f'./Data/processados/itr_cia_aberta_{nome}_{year_0_tri}-{year}.csv', index=False, encoding=\"latin1\")\n",
    "        print(f'ITR {nome} processado')\n",
    "    \n",
    "    # cria uma lista com todos os arquivos fre\n",
    "    arq_fre = [item for item in os.listdir(\"./Data/temp\") if item.startswith(\"fre_cia_aberta_distribuicao_capital_2\")]\n",
    "    fre = pd.DataFrame()\n",
    "\n",
    "    # concatena tudo\n",
    "    for arq in arq_fre[::-1]:\n",
    "        fre = pd.concat([fre, pd.read_csv(f\"./Data/temp/{arq}\", sep=\";\")], axis=0)\n",
    "\n",
    "    # joga fora as linhas com 0\n",
    "    fre = fre[fre[\"Quantidade_Total_Acoes_Circulacao\"] != 0]\n",
    "\n",
    "    # ordena pelo mais recente, retira as duplicatas e pega só as colunas que interessam\n",
    "    fre = fre.sort_values(by=[\"Data_Referencia\", \"Versao\"], ascending=False).drop_duplicates([\"CNPJ_Companhia\"], keep=\"first\", ignore_index=True)[[\"CNPJ_Companhia\", \"Quantidade_Total_Acoes_Circulacao\"]]\n",
    "\n",
    "    # salva em um csv\n",
    "    fre.to_csv(\"./Data/processados/qtd_acoes.csv\", encoding=\"latin1\", index=False)\n",
    "    fre.set_index(\"CNPJ_Companhia\", inplace=True)\n",
    "    print(\"FRE processado\")\n",
    "    \n",
    "        \n",
    "    print(\"Arquivos processados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# só extrai o arquivo dado como parâmetro para a pasta ./Data/temp\n",
    "def extrai_arquivo(arq):\n",
    "    try:\n",
    "        ZipFile(f\"./Data/{arq}\", 'r').extractall('./Data/temp')\n",
    "        print(f\"{arq} extraido\")\n",
    "    except:\n",
    "        print(f\"erro ao extrair {arq}\")\n",
    "\n",
    "# extrai uma lista de arquivos com paralelismo. não roda no jupyter\n",
    "\n",
    "def extrai_paralelo(arquivos_para_extrair):\n",
    "\n",
    "    #  descobre quantas threads tem o CPU atual e cria uma pool para extrair os dados com paralelismo\n",
    "    procs = mp.cpu_count()\n",
    "    pool = Pool(procs)\n",
    "\n",
    "    # cria uma lista de pools para depois dar get\n",
    "    lista_pool = []\n",
    "    for arq in arquivos_para_extrair:\n",
    "        lista_pool.append(pool.apply_async(extrai_arquivo, args=(arq,)))\n",
    "    print(\"Extraindo\")\n",
    "    output = [item.get() for item in lista_pool]\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz o usuario escolher uma empresa\n",
    "def escolhe_empresa():\n",
    "    lista_empresas = \\\n",
    "    pd.read_csv(f\"./Data/processados/dfp_cia_aberta_BPA_{tipo}_{year_0}-{year}.csv\", header=0, sep=\",\")[\n",
    "        [\"DENOM_CIA\", 'CD_CVM']].drop_duplicates()\n",
    "    while True:\n",
    "        busca = input(\"Entre com o nome da empresa: \")\n",
    "        empresa = lista_empresas[lista_empresas['DENOM_CIA'].str.contains(busca, case=False)]\n",
    "        print(empresa)\n",
    "        ok = input(\"A empresa desejada está na primeira linha? (y/n) \")\n",
    "        if ok == \"y\":\n",
    "            return(busca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retorna um df com CNPJ razao social e ticker de todas as empresas listadas em bolsa\n",
    "def cria_lista_empresas(year_0=year_0, year=year, year_0_tri=year_0_tri):\n",
    "\n",
    "    #cria lista de empresas. Concatena consolidado e individual\n",
    "    lista_empresas = pd.read_csv(f\"./Data/processados/dfp_cia_aberta_BPA_con_{year_0}-{year}.csv\", header=0, sep=\",\", )[[\"DENOM_CIA\", 'CD_CVM', \"CNPJ_CIA\"]].drop_duplicates()\n",
    "    lista_empresas = pd.concat([lista_empresas, pd.read_csv(f\"./Data/processados/dfp_cia_aberta_BPA_ind_{year_0}-{year}.csv\", header=0, sep=\",\", )[[\"DENOM_CIA\", 'CD_CVM', \"CNPJ_CIA\"]].drop_duplicates()], ignore_index=True).drop_duplicates(keep=\"first\")\n",
    "    lista_empresas.set_index(\"CNPJ_CIA\", inplace=True)\n",
    "\n",
    "    # coloca tickers do arquivo fca\n",
    "    lista_empresas = lista_empresas.join(pd.read_csv(f\"./Data/processados/{arq_fca}\", header=0, sep=\";\", encoding=\"latin1\").set_index(\"CNPJ_Companhia\")[\"Codigo_Negociacao\"].dropna())\n",
    "\n",
    "    # pega tickers da B3 tbm pq na CVM é incompleto.\n",
    "    # extraí de https://www.b3.com.br/pt_br/produtos-e-servicos/negociacao/renda-variavel/empresas-listadas.htm\n",
    "    # no futuro seria bom automatizar isso com um webscraper\n",
    "    b3 = pd.read_csv(\"./Data/empresas_listadas_b3.csv\", encoding=\"latin1\", sep=\";\")[[\"Razão Social\",\"Código\"]]\n",
    "\n",
    "    # Cria a coluna CNPJ com os dados do index\n",
    "    lista_empresas = lista_empresas.rename_axis('CNPJ').reset_index()\n",
    "\n",
    "    # Junta os dados da b3 no arquivo original\n",
    "    lista_empresas = lista_empresas.merge(b3, left_on=\"DENOM_CIA\", right_on=\"Razão Social\", how=\"left\").drop(columns=[\"Razão Social\"])\n",
    "    \n",
    "    # Dá replace em todas as linhas de \"Codigo_Negociacao\" que não obedecem o padrão \"ABCD1\" ou \"ABCD11\"\n",
    "    lista_empresas[\"Codigo_Negociacao\"].replace(to_replace= r\"^(?!\\D{4}\\d{1,2}$).*\", value= np.nan, regex=True, inplace=True)\n",
    "\n",
    "    # Pega só as 4 primeiras letras da coluna \"Codigo_Negociacao\"\n",
    "    lista_empresas[\"TICKER\"] = lista_empresas[\"Codigo_Negociacao\"].str[:4]\n",
    "    lista_empresas.drop(columns=[\"Codigo_Negociacao\"], inplace=True)\n",
    "    lista_empresas.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Dá replace nos NaN da CVM com o ticker do site da B3\n",
    "    lista_empresas[\"TICKER\"].fillna(lista_empresas[\"Código\"], inplace=True)\n",
    "\n",
    "    # Joga fora a coluna com tickers da B3\n",
    "    lista_empresas.drop(columns=[\"Código\"], inplace=True)\n",
    "    \n",
    "    # joga fora o que não tiver ticker\n",
    "    lista_empresas.dropna(inplace=True)\n",
    "    \n",
    "    #deixa o index como o CNPJ\n",
    "    lista_empresas.set_index(\"CNPJ\")\n",
    "    \n",
    "    # tira linhas duplicadas (tem que ter CNPJ, CD_CVM e TICKER iguais)\n",
    "    lista_empresas.drop_duplicates([\"CNPJ\", \"CD_CVM\", \"TICKER\"], inplace=True)\n",
    "    \n",
    "    #salva em um csv\n",
    "    lista_empresas.to_csv(\"./Data/processados/lista empresas.csv\", encoding=\"latin1\", index=False)\n",
    "    \n",
    "    return(lista_empresas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza\n",
    "\n",
    "# Deleta o conteúdo da pasta processados se existir\n",
    "lista_arquivos = os.listdir(\"./Data/processados/\")\n",
    "lista_arquivos.remove(\".gitignore\")\n",
    "\n",
    "for item in lista_arquivos:\n",
    "    try:\n",
    "        os.remove(f\"./Data/processados/{item}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#deleta pasta temporaria se existir\n",
    "try:\n",
    "    shutil.rmtree(f'./Data/temp')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfp_cia_aberta_2010.zip já esta aqui\n",
      "dfp_cia_aberta_2011.zip já esta aqui\n",
      "dfp_cia_aberta_2012.zip já esta aqui\n",
      "dfp_cia_aberta_2013.zip já esta aqui\n",
      "dfp_cia_aberta_2014.zip já esta aqui\n",
      "dfp_cia_aberta_2015.zip já esta aqui\n",
      "dfp_cia_aberta_2016.zip já esta aqui\n",
      "dfp_cia_aberta_2017.zip já esta aqui\n",
      "dfp_cia_aberta_2018.zip já esta aqui\n",
      "dfp_cia_aberta_2019.zip já esta aqui\n",
      "dfp_cia_aberta_2020.zip já esta aqui\n",
      "dfp_cia_aberta_2021.zip já esta aqui\n",
      "dfp_cia_aberta_2022.zip já esta aqui\n",
      "itr_cia_aberta_2020.zip já esta aqui\n",
      "itr_cia_aberta_2021.zip já esta aqui\n",
      "itr_cia_aberta_2022.zip já esta aqui\n",
      "fca_cia_aberta_2022.zip já esta aqui\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['dfp_cia_aberta_2010.zip',\n",
       "  'dfp_cia_aberta_2011.zip',\n",
       "  'dfp_cia_aberta_2012.zip',\n",
       "  'dfp_cia_aberta_2013.zip',\n",
       "  'dfp_cia_aberta_2014.zip',\n",
       "  'dfp_cia_aberta_2015.zip',\n",
       "  'dfp_cia_aberta_2016.zip',\n",
       "  'dfp_cia_aberta_2017.zip',\n",
       "  'dfp_cia_aberta_2018.zip',\n",
       "  'dfp_cia_aberta_2019.zip',\n",
       "  'dfp_cia_aberta_2020.zip',\n",
       "  'dfp_cia_aberta_2021.zip',\n",
       "  'dfp_cia_aberta_2022.zip'],\n",
       " ['itr_cia_aberta_2020.zip',\n",
       "  'itr_cia_aberta_2021.zip',\n",
       "  'itr_cia_aberta_2022.zip'],\n",
       " ['fca_cia_aberta_2022.zip'],\n",
       " [])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baixa os dados e coloca os nomes dos arquivos baixados em cada variavel\n",
    "arquivos_dfp, arquivos_itr, arquivos_fca, arquivos_fre = baixa_dados(year_0, year, year_0_tri)\n",
    "arquivos_dfp, arquivos_itr, arquivos_fca, arquivos_fre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfp_cia_aberta_2010.zip extraido\n",
      "dfp_cia_aberta_2011.zip extraido\n",
      "dfp_cia_aberta_2012.zip extraido\n",
      "dfp_cia_aberta_2013.zip extraido\n",
      "dfp_cia_aberta_2014.zip extraido\n",
      "dfp_cia_aberta_2015.zip extraido\n",
      "dfp_cia_aberta_2016.zip extraido\n",
      "dfp_cia_aberta_2017.zip extraido\n",
      "dfp_cia_aberta_2018.zip extraido\n",
      "dfp_cia_aberta_2019.zip extraido\n",
      "dfp_cia_aberta_2020.zip extraido\n",
      "dfp_cia_aberta_2021.zip extraido\n",
      "dfp_cia_aberta_2022.zip extraido\n",
      "itr_cia_aberta_2020.zip extraido\n",
      "itr_cia_aberta_2021.zip extraido\n",
      "itr_cia_aberta_2022.zip extraido\n",
      "fca_cia_aberta_2022.zip extraido\n",
      "fre_cia_aberta_2019.zip extraido\n",
      "fre_cia_aberta_2020.zip extraido\n",
      "fre_cia_aberta_2021.zip extraido\n",
      "fre_cia_aberta_2022.zip extraido\n"
     ]
    }
   ],
   "source": [
    "# extrai arquivos\n",
    "arquivos_para_extrair = arquivos_dfp + arquivos_itr + arquivos_fca + arquivos_fre\n",
    "\n",
    "# extrai sequencial\n",
    "for arq in arquivos_para_extrair:\n",
    "    extrai_arquivo(arq)\n",
    "\n",
    "# extrai paralelo, não funciona no jupyter\n",
    "#extrai_paralelo(arquivos_para_extrair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Data/processados/fca_cia_aberta_valor_mobiliario_2022.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pega o nome do arquivo fca que contem os tickers\n",
    "arq_fca = [item for item in os.listdir(\"./Data/temp\") if item.startswith(\"fca_cia_aberta_valor_mobiliario\")]\n",
    "arq_fca = arq_fca[0]\n",
    "\n",
    "# copia o arquivo fca pra pasta processados\n",
    "shutil.copyfile(f\"./Data/temp/{arq_fca}\", f\"./Data/processados/{arq_fca}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando dados\n",
      "DFP BPA_con processado\n",
      "DFP BPA_ind processado\n",
      "DFP BPP_con processado\n",
      "DFP BPP_ind processado\n",
      "DFP DRE_con processado\n",
      "DFP DRE_ind processado\n",
      "DFP DFC_MD_con processado\n",
      "DFP DFC_MI_con processado\n",
      "DFP DFC_MD_ind processado\n",
      "DFP DFC_MI_ind processado\n",
      "ITR BPA_con processado\n",
      "ITR BPA_ind processado\n",
      "ITR BPP_con processado\n",
      "ITR BPP_ind processado\n",
      "ITR DRE_con processado\n",
      "ITR DRE_ind processado\n",
      "ITR DFC_MD_con processado\n",
      "ITR DFC_MI_con processado\n",
      "ITR DFC_MD_ind processado\n",
      "ITR DFC_MI_ind processado\n",
      "Arquivos processados\n"
     ]
    }
   ],
   "source": [
    "# concatena os arquivos baixados do ano inicial até o final\n",
    "processa_dados(year_0, year, year_0_tri)\n",
    "\n",
    "#deleta pasta temporaria se existir\n",
    "try:\n",
    "    shutil.rmtree(f'./Data/temp')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DENOM_CIA</th>\n",
       "      <th>CD_CVM</th>\n",
       "      <th>TICKER</th>\n",
       "      <th>Quantidade_Total_Acoes_Circulacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00.000.000/0001-91</th>\n",
       "      <td>BCO BRASIL S.A.</td>\n",
       "      <td>1023</td>\n",
       "      <td>BBAS</td>\n",
       "      <td>1.420731e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00.000.208/0001-00</th>\n",
       "      <td>BRB BCO DE BRASILIA S.A.</td>\n",
       "      <td>14206</td>\n",
       "      <td>BSLI</td>\n",
       "      <td>4.195216e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00.001.180/0001-26</th>\n",
       "      <td>CENTRAIS ELET BRAS S.A. - ELETROBRAS</td>\n",
       "      <td>2437</td>\n",
       "      <td>ELET</td>\n",
       "      <td>5.997421e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00.070.698/0001-11</th>\n",
       "      <td>CIA ENERGETICA DE BRASILIA</td>\n",
       "      <td>14451</td>\n",
       "      <td>CEBR</td>\n",
       "      <td>1.430870e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00.242.184/0001-04</th>\n",
       "      <td>ARMAC LOCAÇÃO, LOGÍSTICA E SERVIÇOS S.A.</td>\n",
       "      <td>26069</td>\n",
       "      <td>ARML</td>\n",
       "      <td>1.718094e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94.813.102/0001-70</th>\n",
       "      <td>TRÊS TENTOS AGROINDUSTRIAL S/A</td>\n",
       "      <td>25950</td>\n",
       "      <td>TTEN</td>\n",
       "      <td>1.123436e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95.426.862/0001-97</th>\n",
       "      <td>EXCELSIOR ALIMENTOS S.A.</td>\n",
       "      <td>1570</td>\n",
       "      <td>BAUH</td>\n",
       "      <td>1.508636e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96.418.264/0218-02</th>\n",
       "      <td>LOJAS QUERO QUERO S.A.</td>\n",
       "      <td>25038</td>\n",
       "      <td>LJQQ</td>\n",
       "      <td>1.789674e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.191.902/0001-94</th>\n",
       "      <td>CONSERVAS ODERICH S.A.</td>\n",
       "      <td>4693</td>\n",
       "      <td>ODER</td>\n",
       "      <td>1.979520e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.837.181/0001-47</th>\n",
       "      <td>DURATEX S.A.</td>\n",
       "      <td>21091</td>\n",
       "      <td>DXCO</td>\n",
       "      <td>2.748634e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   DENOM_CIA  CD_CVM TICKER  \\\n",
       "00.000.000/0001-91                           BCO BRASIL S.A.    1023   BBAS   \n",
       "00.000.208/0001-00                  BRB BCO DE BRASILIA S.A.   14206   BSLI   \n",
       "00.001.180/0001-26      CENTRAIS ELET BRAS S.A. - ELETROBRAS    2437   ELET   \n",
       "00.070.698/0001-11                CIA ENERGETICA DE BRASILIA   14451   CEBR   \n",
       "00.242.184/0001-04  ARMAC LOCAÇÃO, LOGÍSTICA E SERVIÇOS S.A.   26069   ARML   \n",
       "...                                                      ...     ...    ...   \n",
       "94.813.102/0001-70            TRÊS TENTOS AGROINDUSTRIAL S/A   25950   TTEN   \n",
       "95.426.862/0001-97                  EXCELSIOR ALIMENTOS S.A.    1570   BAUH   \n",
       "96.418.264/0218-02                    LOJAS QUERO QUERO S.A.   25038   LJQQ   \n",
       "97.191.902/0001-94                    CONSERVAS ODERICH S.A.    4693   ODER   \n",
       "97.837.181/0001-47                              DURATEX S.A.   21091   DXCO   \n",
       "\n",
       "                    Quantidade_Total_Acoes_Circulacao  \n",
       "00.000.000/0001-91                       1.420731e+09  \n",
       "00.000.208/0001-00                       4.195216e+07  \n",
       "00.001.180/0001-26                       5.997421e+08  \n",
       "00.070.698/0001-11                       1.430870e+07  \n",
       "00.242.184/0001-04                       1.718094e+08  \n",
       "...                                               ...  \n",
       "94.813.102/0001-70                       1.123436e+08  \n",
       "95.426.862/0001-97                       1.508636e+06  \n",
       "96.418.264/0218-02                       1.789674e+08  \n",
       "97.191.902/0001-94                       1.979520e+05  \n",
       "97.837.181/0001-47                       2.748634e+08  \n",
       "\n",
       "[412 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cria um dataframe com todas as empresas listadas e ticker\n",
    "lista_empresas = cria_lista_empresas(year_0, year, year_0_tri)\n",
    "\n",
    "# muda o index pro CNPJ pra poder dar join\n",
    "lista_empresas.set_index(\"CNPJ\", inplace=True)\n",
    "\n",
    "# coloca a quantidade de ações em circulação e tira as que não tem\n",
    "lista_empresas = lista_empresas.join(fre).dropna()\n",
    "lista_empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular indicadores e colocar cotação (adiar ao maximo pq demora mto tempo pra pegar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
